{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pentathlon-III: Next Product to Buy Models\n",
    "\n",
    "* Team-lead GitLab userid:\n",
    "* Group name:\n",
    "* Team member names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrsm as rsm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# increase plot resolution\n",
    "# mpl.rcParams[\"figure.dpi\"] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the data - this dataset must NOT be changed\n",
    "pentathlon_nptb = pd.read_pickle(\"data/pentathlon_nptb.pkl\")\n",
    "pentathlon_nptb[\"buyer_yes\"] = (pentathlon_nptb[\"buyer\"] == \"yes\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pent = pentathlon_nptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For our neural network model, we created dummy variables for the categorical variables, age, gender, and message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variables created for gender\n",
    "pent[\"gender\"] = pd.get_dummies(pent[\"gender\"])\n",
    "pent[\n",
    "    [\"under_thirty\", \"thirty_to_fortyfour\", \"fortyfive_to_fiftynine\", \"sixty_and_above\"]\n",
    "] = pd.get_dummies(pent[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvar = \"buyer_yes\"\n",
    "evar = [\n",
    "    \"income\",\n",
    "    \"education\",\n",
    "    \"children\",\n",
    "    \"gender\",\n",
    "    \"under_thirty\",\n",
    "    \"thirty_to_fortyfour\",\n",
    "    \"fortyfive_to_fiftynine\",\n",
    "    \"sixty_and_above\",\n",
    "    \"freq_endurance\",\n",
    "    \"freq_strength\",\n",
    "    \"freq_water\",\n",
    "    \"freq_team\",\n",
    "    \"freq_backcountry\",\n",
    "    \"freq_winter\",\n",
    "    \"freq_racquet\",\n",
    "    \"message_endurance\",\n",
    "    \"message_strength\",\n",
    "    \"message_water\",\n",
    "    \"message_team\",\n",
    "    \"message_backcountry\",\n",
    "    \"message_winter\",\n",
    "    \"message_racquet\",\n",
    "]\n",
    "std_var = [\n",
    "    \"education\",\n",
    "    \"children\",\n",
    "    \"income\",\n",
    "    \"freq_endurance\",\n",
    "    \"freq_strength\",\n",
    "    \"freq_water\",\n",
    "    \"freq_team\",\n",
    "    \"freq_backcountry\",\n",
    "    \"freq_winter\",\n",
    "    \"freq_racquet\",\n",
    "]\n",
    "\n",
    "idvar = \"custid\"\n",
    "lev = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "# standardization-- when standardizing, do we look at training == 1 or do we look at representative == 1?\n",
    "X_colnames = pent.loc[\n",
    "    [0],\n",
    "    [\n",
    "        \"education\",\n",
    "        \"children\",\n",
    "        \"income\",\n",
    "        \"freq_endurance\",\n",
    "        \"freq_strength\",\n",
    "        \"freq_water\",\n",
    "        \"freq_team\",\n",
    "        \"freq_backcountry\",\n",
    "        \"freq_winter\",\n",
    "        \"freq_racquet\",\n",
    "    ],\n",
    "].columns\n",
    "scaler = preprocessing.StandardScaler()\n",
    "sf = scaler.fit(pent.query(\"training == 1\")[X_colnames])\n",
    "pent_std = pent.copy()\n",
    "\n",
    "# new standardized cols\n",
    "pent_std[std_var] = sf.transform(pent[X_colnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variables created for message\n",
    "pq = pd.get_dummies(pent_std[[\"message\"]])\n",
    "pent_std = pent_std.join(pq)\n",
    "train = pent_std[pent_std[\"training\"] == 1]\n",
    "test = pent_std[pent_std[\"training\"] == 0]\n",
    "rep = pent_std[pent_std[\"representative\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing sets created for training and representative\n",
    "eval_dat = pd.concat([train, test, rep], axis=0)\n",
    "eval_dat = eval_dat[[idvar, rvar, \"training\", \"representative\"]]\n",
    "X_train = train[evar]\n",
    "y_train = train[rvar]\n",
    "X_test = test[evar]\n",
    "y_test = test[rvar]\n",
    "X_rep = rep[evar]\n",
    "y_rep = rep[rvar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full sets created for training and representative\n",
    "# X_full = pent_std[evar]\n",
    "# y_full = pent_std[rvar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net from SKLEARN\n",
    "clf = MLPClassifier(\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=0.45,\n",
    "    hidden_layer_sizes=(4,),\n",
    "    random_state=1234,\n",
    "    max_iter=10000,\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [X_train, X_test]\n",
    "Xs = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC training data for neural network model: 88.46%\n",
      "AUC testing data for neural network model: 88.45%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_2_tr = clf.predict_proba(X_train)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, pred_2_tr[:, 1])\n",
    "\n",
    "pred_2_test = clf.predict_proba(X_test)\n",
    "fpr_t, tpr_t, thresholds_t = metrics.roc_curve(y_test, pred_2_test[:, 1])\n",
    "\n",
    "print(f\"AUC training data for neural network model: {(metrics.auc(fpr, tpr) * 100).round(2)}%\")\n",
    "print(f\"AUC testing data for neural network model: {(metrics.auc(fpr_t, tpr_t) * 100).round(2)}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation/GridSearchCV below is commented out to help performance times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CV for NN\n",
    "# nr_hnodes = range(2, 5)\n",
    "# hls = list(zip(nr_hnodes)) + list(zip(nr_hnodes, nr_hnodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alpha is the level of regularization\n",
    "# param_grid = {\n",
    "#     \"hidden_layer_sizes\": hls,\n",
    "#     \"alpha\": [0.4, 0.45, 0.5],\n",
    "#     \"random_state\": [1234],\n",
    "# }\n",
    "# scoring = {\"AUC\": \"roc_auc\"}\n",
    "\n",
    "# clf_cv = GridSearchCV(\n",
    "#     clf,\n",
    "#     param_grid,\n",
    "#     scoring=scoring,\n",
    "#     cv=5,\n",
    "#     n_jobs=4,\n",
    "#     refit=\"AUC\",\n",
    "#     verbose=5,\n",
    "# )\n",
    "# clf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on final model\n",
    "# strength\n",
    "strength_test = X_test.copy()\n",
    "strength_train = X_train.copy()\n",
    "# strength_test[\"message_strength\"]=1\n",
    "# strength_test[[\"message_endurance\",\t\"message_water\", \"message_team\",\"message_backcountry\",\"message_winter\",\"message_racquet\"]]=0\n",
    "# strength_train[\"message_strength\"]=1\n",
    "# strength_train[[\"message_endurance\", \"message_water\", \"message_team\",\"message_backcountry\",\"message_winter\",\"message_racquet\"]]=0\n",
    "# strength_test\n",
    "strength_rep = X_rep.copy()\n",
    "strength_rep[\"message_strength\"] = 1\n",
    "strength_rep[\n",
    "    [\n",
    "        \"message_racquet\",\n",
    "        \"message_water\",\n",
    "        \"message_team\",\n",
    "        \"message_backcountry\",\n",
    "        \"message_winter\",\n",
    "        \"message_endurance\",\n",
    "    ]\n",
    "] = 0\n",
    "\n",
    "eval_dat[\"strength_p\"] = 0\n",
    "eval_dat.loc[eval_dat.representative == 1, \"strength_p\"] = clf.predict_proba(\n",
    "    strength_rep\n",
    ")[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 1, \"strength_p\"] = clf.predict_proba(strength_train)[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 0, \"strength_p\"] = clf.predict_proba(strength_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on final model\n",
    "# strength\n",
    "strength_test = X_test.copy()\n",
    "strength_train = X_train.copy()\n",
    "# strength_test[\"message_endurance\"]=1\n",
    "# strength_test[[\"message_strength\",\t\"message_water\", \"message_team\",\"message_backcountry\",\"message_winter\",\"message_racquet\"]]=0\n",
    "# strength_train[\"message_endurance\"]=1\n",
    "# strength_train[[\"message_strength\", \"message_water\", \"message_team\",\"message_backcountry\",\"message_winter\",\"message_racquet\"]]=0\n",
    "# strength_test\n",
    "strength_rep = X_rep.copy()\n",
    "strength_rep[\"message_endurance\"] = 1\n",
    "strength_rep[\n",
    "    [\n",
    "        \"message_strength\",\n",
    "        \"message_water\",\n",
    "        \"message_team\",\n",
    "        \"message_backcountry\",\n",
    "        \"message_winter\",\n",
    "        \"message_racquet\",\n",
    "    ]\n",
    "] = 0\n",
    "\n",
    "eval_dat[\"endurance_p\"] = 0\n",
    "eval_dat.loc[eval_dat.representative == 1, \"endurace_p\"] = clf.predict_proba(\n",
    "    strength_rep\n",
    ")[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 1, \"endurance_p\"] = clf.predict_proba(strength_train)[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 0, \"endurance_p\"] = clf.predict_proba(strength_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on final model\n",
    "# strength\n",
    "strength_test = X_test.copy()\n",
    "strength_train = X_train.copy()\n",
    "# strength_test[\"message_water\"]=1\n",
    "# strength_test[[\"message_strength\",\t\"message_endurance\", \"message_team\",\"message_backcountry\",\"message_winter\",\"message_racquet\"]]=0\n",
    "# strength_train[\"message_water\"]=1\n",
    "# strength_train[[\"message_strength\", \"message_endurance\", \"message_team\",\"message_backcountry\",\"message_winter\",\"message_racquet\"]]=0\n",
    "# strength_test\n",
    "strength_rep = X_rep.copy()\n",
    "# print(strength_rep.shape)\n",
    "strength_rep[\"message_water\"] = 1\n",
    "strength_rep[\n",
    "    [\n",
    "        \"message_strength\",\n",
    "        \"message_endurance\",\n",
    "        \"message_team\",\n",
    "        \"message_backcountry\",\n",
    "        \"message_winter\",\n",
    "        \"message_racquet\",\n",
    "    ]\n",
    "] = 0\n",
    "\n",
    "eval_dat[\"water_p\"] = 0\n",
    "eval_dat.loc[eval_dat.representative == 1, \"water_p\"] = clf.predict_proba(strength_rep)[\n",
    "    :, 1\n",
    "]\n",
    "# eval_dat.loc[eval_dat.training == 1, \"water_p\"] = clf.predict_proba(strength_train)[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 0, \"water_p\"] = clf.predict_proba(strength_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on final model\n",
    "# strength\n",
    "strength_test = X_test.copy()\n",
    "strength_train = X_train.copy()\n",
    "# strength_test[\"message_team\"]=1\n",
    "# strength_test[[\"message_strength\",\t\"message_endurance\", \"message_water\",\"message_backcountry\",\"message_winter\",\"message_racquet\"]]=0\n",
    "# strength_train[\"message_team\"]=1\n",
    "# strength_train[[\"message_strength\", \"message_endurance\", \"message_water\",\"message_backcountry\",\"message_winter\",\"message_racquet\"]]=0\n",
    "# strength_test\n",
    "strength_rep = X_rep.copy()\n",
    "strength_rep[\"message_team\"] = 1\n",
    "strength_rep[\n",
    "    [\n",
    "        \"message_strength\",\n",
    "        \"message_water\",\n",
    "        \"message_racquet\",\n",
    "        \"message_backcountry\",\n",
    "        \"message_winter\",\n",
    "        \"message_endurance\",\n",
    "    ]\n",
    "] = 0\n",
    "\n",
    "eval_dat[\"team_p\"] = 0\n",
    "eval_dat.loc[eval_dat.representative == 1, \"team_p\"] = clf.predict_proba(strength_rep)[\n",
    "    :, 1\n",
    "]\n",
    "# eval_dat.loc[eval_dat.training == 1, \"team_p\"] = clf.predict_proba(strength_train)[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 0, \"team_p\"] = clf.predict_proba(strength_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on final model\n",
    "# strength\n",
    "strength_test = X_test.copy()\n",
    "strength_train = X_train.copy()\n",
    "# strength_test[\"message_racquet\"]=1\n",
    "# strength_test[[\"message_strength\",\t\"message_water\", \"message_team\",\"message_backcountry\",\"message_winter\",\"message_endurance\"]]=0\n",
    "# strength_train[\"message_racquet\"]=1\n",
    "# strength_train[[\"message_strength\", \"message_water\", \"message_team\",\"message_backcountry\",\"message_winter\",\"message_endurance\"]]=0\n",
    "# strength_test\n",
    "strength_rep = X_rep.copy()\n",
    "strength_rep[\"message_racquet\"] = 1\n",
    "strength_rep[\n",
    "    [\n",
    "        \"message_strength\",\n",
    "        \"message_water\",\n",
    "        \"message_team\",\n",
    "        \"message_backcountry\",\n",
    "        \"message_winter\",\n",
    "        \"message_endurance\",\n",
    "    ]\n",
    "] = 0\n",
    "\n",
    "eval_dat[\"racquet_p\"] = 0\n",
    "eval_dat.loc[eval_dat.representative == 1, \"racquet_p\"] = clf.predict_proba(\n",
    "    strength_rep\n",
    ")[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 1, \"racquet_p\"] = clf.predict_proba(strength_train)[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 0, \"racquet_p\"] = clf.predict_proba(strength_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on final model\n",
    "# strength\n",
    "strength_test = X_test.copy()\n",
    "strength_train = X_train.copy()\n",
    "# strength_test[\"message_winter\"]=1\n",
    "# strength_test[[\"message_strength\",\t\"message_water\", \"message_team\",\"message_backcountry\",\"message_racquet\",\"message_endurance\"]]=0\n",
    "# strength_train[\"message_winter\"]=1\n",
    "# strength_train[[\"message_strength\", \"message_water\", \"message_team\",\"message_backcountry\",\"message_racquet\",\"message_endurance\"]]=0\n",
    "# strength_test\n",
    "strength_rep = X_rep.copy()\n",
    "strength_rep[\"message_winter\"] = 1\n",
    "strength_rep[\n",
    "    [\n",
    "        \"message_strength\",\n",
    "        \"message_water\",\n",
    "        \"message_team\",\n",
    "        \"message_backcountry\",\n",
    "        \"message_racquet\",\n",
    "        \"message_endurance\",\n",
    "    ]\n",
    "] = 0\n",
    "\n",
    "eval_dat[\"winter_p\"] = 0\n",
    "eval_dat.loc[eval_dat.representative == 1, \"winter_p\"] = clf.predict_proba(\n",
    "    strength_rep\n",
    ")[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 1, \"winter_p\"] = clf.predict_proba(strength_train)[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 0, \"winter_p\"] = clf.predict_proba(strength_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on final model\n",
    "# strength\n",
    "strength_test = X_test.copy()\n",
    "strength_train = X_train.copy()\n",
    "strength_rep = X_rep.copy()\n",
    "\n",
    "# strength_test[\"message_backcountry\"]=1\n",
    "# strength_test[[\"message_strength\",\t\"message_water\", \"message_team\",\"message_winter\",\"message_racquet\",\"message_endurance\"]]=0\n",
    "# strength_train[\"message_backcountry\"]=1\n",
    "# strength_train[[\"message_strength\", \"message_water\", \"message_team\",\"message_winter\",\"message_racquet\",\"message_endurance\"]]=0\n",
    "strength_rep[\"message_backcountry\"] = 1\n",
    "strength_rep[\n",
    "    [\n",
    "        \"message_strength\",\n",
    "        \"message_water\",\n",
    "        \"message_team\",\n",
    "        \"message_winter\",\n",
    "        \"message_racquet\",\n",
    "        \"message_endurance\",\n",
    "    ]\n",
    "] = 0\n",
    "\n",
    "eval_dat[\"backcountry_p\"] = 0\n",
    "# eval_dat.loc[eval_dat.training == 1, \"backcountry_p\"] = clf.predict_proba(strength_train)[:, 1]\n",
    "# eval_dat.loc[eval_dat.training == 0, \"backcountry_p\"] = clf.predict_proba(strength_test)[:, 1]\n",
    "eval_dat.loc[eval_dat.representative == 1, \"backcountry_p\"] = clf.predict_proba(\n",
    "    strength_rep\n",
    ")[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the message that will result in the highest profit for each customer\n",
    "eval_dat[\"to_offer_i\"] = (\n",
    "    eval_dat[\n",
    "        [\n",
    "            \"strength_p\",\n",
    "            \"water_p\",\n",
    "            \"team_p\",\n",
    "            \"backcountry_p\",\n",
    "            \"winter_p\",\n",
    "            \"racquet_p\",\n",
    "            \"endurance_p\",\n",
    "        ]\n",
    "    ]\n",
    "    .idxmax(axis=1)\n",
    "    .str.replace(\"strength_p\", \"strength\")\n",
    "    .replace(\"water_p\", \"water\")\n",
    "    .replace(\"team_p\", \"team\")\n",
    "    .replace(\"backcountry_p\", \"backcountry\")\n",
    "    .replace(\"winter_p\", \"winter\")\n",
    "    .replace(\"racquet_p\", \"racquet\")\n",
    "    .replace(\"endurance_p\", \"endurance\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the predctions for each of the messages, get the prediction of the value\n",
    "eval_dat[\"p_target_i\"] = eval_dat[\n",
    "    [\n",
    "        \"strength_p\",\n",
    "        \"water_p\",\n",
    "        \"team_p\",\n",
    "        \"backcountry_p\",\n",
    "        \"winter_p\",\n",
    "        \"racquet_p\",\n",
    "        \"endurance_p\",\n",
    "    ]\n",
    "].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the entire 200K customers, get the percentage of customers for whom each message type will lead to the highest probability of purchase\n",
    "full_perc = eval_dat[\n",
    "    [\n",
    "        \"strength_p\",\n",
    "        \"water_p\",\n",
    "        \"team_p\",\n",
    "        \"backcountry_p\",\n",
    "        \"winter_p\",\n",
    "        \"racquet_p\",\n",
    "        \"endurance_p\",\n",
    "        \"p_target_i\",\n",
    "    ]\n",
    "].agg(\"mean\").sort_values(ascending=True).apply(rsm.format_nr, perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Determine the message (i.e., endurance, strength, water, team, backcountry, winter, or racquet) predicted to lead to the highest probability of purchase. Describe your approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df to deal just with the representative data for questions 1-8\n",
    "reps = eval_dat[eval_dat[\"representative\"] == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>to_offer_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U45198803</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U22197752</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U19423462</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U23888305</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U16954857</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>U12620333</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>U18623424</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>U64468968</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>U33721691</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>U23361779</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          custid to_offer_i\n",
       "0      U45198803   strength\n",
       "1      U22197752   strength\n",
       "2      U19423462   strength\n",
       "3      U23888305   strength\n",
       "4      U16954857   strength\n",
       "...          ...        ...\n",
       "99995  U12620333   strength\n",
       "99996  U18623424   strength\n",
       "99997  U64468968   strength\n",
       "99998  U33721691   strength\n",
       "99999  U23361779   strength\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each customer, the message that will lead to the highest probability of purchase\n",
    "reps[[\"custid\", \"to_offer_i\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the neural network, we predicted that strength was the message that would lead us to the highest probability for every customer. We also ran the model on the 5M dataset and the model led us to predict similar results.This obviously is unrealistic and we determined that the neural network would not be an accurate model for us to predict which message would lead to the highest probability of purchase. Our approach was that, in order to get reasonable predictions, without them all being equal for each message variable, we would have to set each message dummy variable to 1 and the rest to zero, making 7 predictions in total for each (this has been commented out in the code blocks above). This yielded us poor results, so we made another attempt at making predictions on the representative data, while fitting the model on the training and testing data. This also yielded us similar results with one message type dominating across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: For each message, report the percentage of customers for whom that message maximizes their probability of purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the 7 message types, plus targeting apprach, the percentage of customers for whom that message maximizes their probability of purchase\n",
    "nn_q2 = reps['to_offer_i'].value_counts(normalize = True)*100\n",
    "nn_q2 = pd.DataFrame(nn_q2)\n",
    "nn_q2.columns = ['customers (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customers (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>strength</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          customers (%)\n",
       "strength          100.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each message type, our model predicts that strength will maximize 99.99% of our customers probability of purchase for the representative data. Applying this model to the 5M dataset also yielded us with similar results, with one message dominating the probability of purchase over the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, because of the results of the previous two questions, we decided not to continue on with using this model to answer the next questions and focus our efforts on fine-tuning model types that will provide us with better predictions. The neural network did not give us the predictions we were hoping for, likely because of the type of data at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
